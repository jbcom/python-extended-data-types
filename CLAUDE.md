

<!-- Source: .ruler/AGENTS.md -->

# Extended Data Types - AI Agent Instructions

This is the central source of truth for AI agent instructions in this repository.
Rules defined here are distributed to all supported AI coding assistants via Ruler.

## Project Overview

Extended Data Types is a Python utility library providing enhanced functionality for working with common data formats and types. It serves as a reliable, typed utility layer for Python applications.

### Core Purpose

- **Serialization utilities**: Safe, typed helpers for YAML, JSON, TOML, HCL, and Base64
- **File system operations**: Platform-aware path handling, Git discovery, encoding detection
- **Data structure manipulation**: Enhanced list and dictionary operations
- **String transformations**: Case conversion, humanization, pluralization
- **Type utilities**: Safe type conversion and validation

### Key Design Principles

- **Type safety**: Full type annotations and mypy compliance
- **Reliability**: Comprehensive test coverage with automated CI/CD
- **Ergonomics**: Clean, intuitive APIs
- **Platform awareness**: Handles cross-platform differences gracefully
- **Production ready**: No shortcuts, placeholders, or experimental features

## Technology Stack

- **Package manager**: `uv` (fast, Rust-based)
- **Build backend**: `hatchling`
- **Configuration**: `pyproject.toml`
- **Python versions**: 3.9+
- **Linting & formatting**: `ruff`
- **Type checking**: `mypy` (strict mode)
- **Testing**: `pytest`
- **CI/CD**: GitHub Actions with semantic-release



<!-- Source: .ruler/00-fundamentals.md -->

# Fundamentals

## Before Acting

1. **Read before modifying** - Always read the file/code before editing
2. **Run builds after changes** - Verify your changes compile/lint
3. **Check git status** - Know what you're committing

## Making Changes

1. **One concern per commit** - Keep commits focused
2. **Run linters/tests locally** before pushing
3. **Don't consolidate code** without verifying the build

## When Copying/Moving Files

1. Read the file first
2. Check if content is relevant to destination
3. Update paths and references
4. Remove tool-specific cruft that doesn't apply

## Authentication

```bash
# jbcom repos - ALWAYS use this pattern
GH_TOKEN="$GITHUB_TOKEN" gh <command>
```

## Session Management

```bash
# Start of session
cat memory-bank/activeContext.md 2>/dev/null || echo "No memory bank"
gh issue list --label agent-session 2>/dev/null || true

# End of session - update context
echo "## Session: $(date +%Y-%m-%d)" >> memory-bank/activeContext.md
```



<!-- Source: .ruler/01-pr-workflow.md -->

# PR Workflow

## Creating PRs

1. **One feature/fix per PR** - Keep scope minimal
2. **Clear title**: `type(scope): description`
3. **Body explains** WHAT, WHY, and HOW

### Conventional Commit Types

| Type | Use Case |
|------|----------|
| `feat` | New feature - minor bump |
| `fix` | Bug fix - patch bump |
| `docs` | Documentation only |
| `chore` | Maintenance tasks |
| `refactor` | Code restructuring |
| `test` | Adding tests |

## AI Peer Review

**ALWAYS request AI reviews on PRs:**

```
/gemini review
/q review
@copilot review
```

## Addressing Feedback

1. Make commits that fix issues
2. Respond to EVERY comment (fix OR explain why not)
3. Re-request review after significant changes

### Resolving Review Threads

```bash
# Via GraphQL (preferred for batch resolution)
gh api graphql -f query='mutation {
  resolveReviewThread(input: {threadId: "PRRT_xxx"}) {
    thread { isResolved }
  }
}'
```

## Merging

- Wait for CI to pass
- Address all review comments
- Squash if commits are messy
- Never use `--admin` to bypass checks



<!-- Source: .ruler/02-memory-bank.md -->

# Memory Bank Protocol

## Purpose

Memory bank provides session continuity between agent runs. It's the "living memory" pattern.

## Files

| File | Purpose |
|------|---------|
| `memory-bank/activeContext.md` | Current state and focus |
| `memory-bank/progress.md` | Session-by-session log |

## Session Start

```bash
# Check context
if [ -f memory-bank/activeContext.md ]; then
  cat memory-bank/activeContext.md
fi

# Check for open issues
gh issue list --label agent-session 2>/dev/null || true
```

## Session End

```bash
# Update context
cat >> memory-bank/activeContext.md << 'EOF'

## Session: $(date +%Y-%m-%d)

### Completed
- [x] Task 1

### For Next Agent
- [ ] Follow-up task
EOF

# Commit if changes
git add memory-bank/
git commit -m "docs: update memory bank for handoff" || true
```

## Handoff Notes

When ending a session:

1. **Summarize completed work** - What got done
2. **List outstanding tasks** - What's left
3. **Document blockers** - What stopped progress
4. **Include references** - PRs, issues, file paths



<!-- Source: .ruler/03-ci-workflow.md -->

# CI/CD Workflow

## Branch Protection

- **main**: Protected, requires PR and CI pass
- **Feature branches**: `feat/`, `fix/`, `docs/`, `chore/`

## CI Checks

Every PR must pass:

1. **Build** - Package compiles/builds
2. **Test** - All tests pass
3. **Lint** - No linting errors
4. **Type check** - No type errors

## Watching CI

```bash
# List recent runs
gh run list --limit 5

# Watch a specific run
gh run watch <run-id>

# View run logs
gh run view <run-id> --log
```

## Fixing CI Failures

### Build Failures

```bash
# Python
uv sync && uv run pytest

# TypeScript
pnpm install && pnpm run build

# Go
go mod download && go build ./...
```

### Lint Failures

```bash
# Python
uvx ruff check --fix .
uvx ruff format .

# TypeScript
pnpm run lint:fix

# Go
golangci-lint run --fix
```

### Test Failures

1. Read the failure output carefully
2. Reproduce locally
3. Fix the code or the test
4. Verify fix locally before pushing

## Required Secrets

These secrets power CI/CD:

| Secret | Purpose |
|--------|---------|
| `CI_GITHUB_TOKEN` | GitHub API access |
| `PYPI_TOKEN` | PyPI publishing |
| `NPM_TOKEN` | npm publishing |
| `DOCKERHUB_USERNAME` | Docker Hub login |
| `DOCKERHUB_TOKEN` | Docker Hub publishing |

## Troubleshooting

### "Permission denied"

Token lacks required scopes. Check:
- `repo` scope for repository access
- `workflow` scope for Actions
- `write:packages` for package publishing

### "Rate limit exceeded"

Use authenticated requests:
```bash
GH_TOKEN="$GITHUB_JBCOM_TOKEN" gh api ...
```



<!-- Source: .ruler/04-releases.md -->

# Releases

## Versioning

All packages use **Semantic Versioning (SemVer)**: `MAJOR.MINOR.PATCH`

- **MAJOR**: Breaking changes
- **MINOR**: New features (backward compatible)
- **PATCH**: Bug fixes (backward compatible)

## Conventional Commits

Commits drive automatic version bumps:

```
feat(scope): new feature       - minor bump (x.Y.0)
fix(scope): bug fix            - patch bump (x.y.Z)
feat(scope)!: breaking change  - major bump (X.0.0)
```

### Package Scopes

| Scope | Package |
|-------|---------|
| `edt` | extended-data-types |
| `logging` | lifecyclelogging |
| `dic` | directed-inputs-class |
| `bridge` | python-terraform-bridge |
| `connectors` | vendor-connectors |
| `agentic` | agentic-control |
| `vss` | vault-secret-sync |

## Release Process

```
Push to main with conventional commit
        |
CI runs tests & lint
        |
Semantic release analyzes commits
        |
Version bumped automatically
        |
Package published (PyPI/npm/Docker)
        |
Synced to public repo
```

## What NOT to Do

- **Never** manually edit `__version__` or `package.json` version
- **Never** create tags by hand
- **Never** skip CI for releases
- **Never** suggest alternative versioning schemes

## Checking Release Status

```bash
# Check if release will happen
semantic-release --noop version --print

# Check recent releases
gh release list --limit 5

# Check CI status
gh run list --limit 3
```



<!-- Source: .ruler/05-development.md -->

# Development Guidelines

## Core Philosophy

Write clean, tested, production-ready code. No shortcuts, no placeholders.

## Development Flow

1. **Read the requirements** from specs or issues
2. **Write tests first** (TDD approach)
3. **Implement the feature** completely
4. **Run linting**: `uvx ruff check src/ tests/`
5. **Run tests**: `uv run pytest tests/`
6. **Commit** with conventional commits

## Testing Commands

```bash
# Install dependencies
uv sync --extra tests

# Run tests
uv run pytest tests/ -v

# Run with coverage
uv run pytest tests/ --cov=src/ --cov-report=term-missing

# Linting
uvx ruff check src/ tests/
uvx ruff format src/ tests/

# Type checking
uvx mypy src/
```

## Commit Messages

Use conventional commits:
- `feat(scope): description` - minor bump
- `fix(scope): description` - patch bump
- `feat!: breaking change` - major bump

## Quality Standards

- All tests passing
- No linter errors
- Complete type annotations
- Proper error handling
- No TODOs or placeholders
- No shortcuts



<!-- Source: .ruler/languages/python.md -->

# Python Standards

## Style

- **Formatter**: Ruff (Black-compatible, 88 char line length)
- **Imports**: Sorted by ruff
- **Type hints**: Required on all public functions

```bash
# Format and lint
uvx ruff check --fix .
uvx ruff format .
```

## Naming

| Element | Convention | Example |
|---------|------------|---------|
| Functions/Variables | snake_case | `get_data()` |
| Classes | PascalCase | `DataProcessor` |
| Constants | UPPER_CASE | `MAX_RETRIES` |
| Private | Leading underscore | `_internal_helper()` |

## Type Hints

```python
# Modern style (Python 3.9+)
from collections.abc import Mapping, Sequence
from typing import Any

def process(items: list[dict[str, Any]]) -> dict[str, int]:
    return {"count": len(items)}

# Legacy style - avoid
from typing import Dict, List
def process(items: Dict[str, Any]) -> List[str]: ...
```

## Package Management

- **Tool**: uv (fast, Rust-based)
- **Config**: `pyproject.toml`
- **Lock file**: `uv.lock` (commit this)

```bash
# Install dependencies
uv sync

# Add dependency
uv add requests

# Add dev dependency
uv add --dev pytest
```

## Testing

- **Framework**: pytest
- **Location**: `tests/` directory
- **Run**: `pytest` or `tox -e <package>`

```bash
# Run tests
pytest

# With coverage
pytest --cov=src

# Specific test
pytest tests/test_utils.py::test_specific
```

## Imports

```python
# Use pathlib
from pathlib import Path
config = Path("config.yaml")

# Avoid os.path
import os
config = os.path.join("config.yaml")
```

## Docstrings

Use Google style:

```python
def process_items(items: list[dict], validate: bool = True) -> dict[str, Any]:
    """Process items and return summary.

    Args:
        items: List of item dictionaries.
        validate: Whether to validate before processing.

    Returns:
        Dictionary with processing results.

    Raises:
        ValueError: If items list is empty.
    """
```
